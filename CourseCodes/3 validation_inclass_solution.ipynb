{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href='https://ai.meng.duke.edu'> = <img align=\"left\" style=\"padding-top:10px;\" src=https://storage.googleapis.com/aipi_datasets/Duke-AIPI-Logo.png>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Selection & Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we are going to look at strategies to divide your dataset in order to perform model selection and testing using subsets of data in ways that do not create bias in your measurement of model performance.\n",
    "\n",
    "We are going to use a dataset which comes from a study done to try to use sonar signals to differentiate between a mine (simulated using a metal cylinder) and a rock.  Details on the dataset can be found [here](https://archive.ics.uci.edu/ml/datasets/Connectionist+Bench+(Sonar,+Mines+vs.+Rocks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the libraries we know we need\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(208, 61)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0200</td>\n",
       "      <td>0.0371</td>\n",
       "      <td>0.0428</td>\n",
       "      <td>0.0207</td>\n",
       "      <td>0.0954</td>\n",
       "      <td>0.0986</td>\n",
       "      <td>0.1539</td>\n",
       "      <td>0.1601</td>\n",
       "      <td>0.3109</td>\n",
       "      <td>0.2111</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0027</td>\n",
       "      <td>0.0065</td>\n",
       "      <td>0.0159</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>0.0167</td>\n",
       "      <td>0.0180</td>\n",
       "      <td>0.0084</td>\n",
       "      <td>0.0090</td>\n",
       "      <td>0.0032</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0453</td>\n",
       "      <td>0.0523</td>\n",
       "      <td>0.0843</td>\n",
       "      <td>0.0689</td>\n",
       "      <td>0.1183</td>\n",
       "      <td>0.2583</td>\n",
       "      <td>0.2156</td>\n",
       "      <td>0.3481</td>\n",
       "      <td>0.3337</td>\n",
       "      <td>0.2872</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0084</td>\n",
       "      <td>0.0089</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0094</td>\n",
       "      <td>0.0191</td>\n",
       "      <td>0.0140</td>\n",
       "      <td>0.0049</td>\n",
       "      <td>0.0052</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0262</td>\n",
       "      <td>0.0582</td>\n",
       "      <td>0.1099</td>\n",
       "      <td>0.1083</td>\n",
       "      <td>0.0974</td>\n",
       "      <td>0.2280</td>\n",
       "      <td>0.2431</td>\n",
       "      <td>0.3771</td>\n",
       "      <td>0.5598</td>\n",
       "      <td>0.6194</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0232</td>\n",
       "      <td>0.0166</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>0.0180</td>\n",
       "      <td>0.0244</td>\n",
       "      <td>0.0316</td>\n",
       "      <td>0.0164</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>0.0078</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.0171</td>\n",
       "      <td>0.0623</td>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.0368</td>\n",
       "      <td>0.1098</td>\n",
       "      <td>0.1276</td>\n",
       "      <td>0.0598</td>\n",
       "      <td>0.1264</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0121</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>0.0150</td>\n",
       "      <td>0.0085</td>\n",
       "      <td>0.0073</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>0.0040</td>\n",
       "      <td>0.0117</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0762</td>\n",
       "      <td>0.0666</td>\n",
       "      <td>0.0481</td>\n",
       "      <td>0.0394</td>\n",
       "      <td>0.0590</td>\n",
       "      <td>0.0649</td>\n",
       "      <td>0.1209</td>\n",
       "      <td>0.2467</td>\n",
       "      <td>0.3564</td>\n",
       "      <td>0.4459</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0031</td>\n",
       "      <td>0.0054</td>\n",
       "      <td>0.0105</td>\n",
       "      <td>0.0110</td>\n",
       "      <td>0.0015</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0107</td>\n",
       "      <td>0.0094</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0       1       2       3       4       5       6       7       8   \\\n",
       "0  0.0200  0.0371  0.0428  0.0207  0.0954  0.0986  0.1539  0.1601  0.3109   \n",
       "1  0.0453  0.0523  0.0843  0.0689  0.1183  0.2583  0.2156  0.3481  0.3337   \n",
       "2  0.0262  0.0582  0.1099  0.1083  0.0974  0.2280  0.2431  0.3771  0.5598   \n",
       "3  0.0100  0.0171  0.0623  0.0205  0.0205  0.0368  0.1098  0.1276  0.0598   \n",
       "4  0.0762  0.0666  0.0481  0.0394  0.0590  0.0649  0.1209  0.2467  0.3564   \n",
       "\n",
       "       9   ...      51      52      53      54      55      56      57  \\\n",
       "0  0.2111  ...  0.0027  0.0065  0.0159  0.0072  0.0167  0.0180  0.0084   \n",
       "1  0.2872  ...  0.0084  0.0089  0.0048  0.0094  0.0191  0.0140  0.0049   \n",
       "2  0.6194  ...  0.0232  0.0166  0.0095  0.0180  0.0244  0.0316  0.0164   \n",
       "3  0.1264  ...  0.0121  0.0036  0.0150  0.0085  0.0073  0.0050  0.0044   \n",
       "4  0.4459  ...  0.0031  0.0054  0.0105  0.0110  0.0015  0.0072  0.0048   \n",
       "\n",
       "       58      59  60  \n",
       "0  0.0090  0.0032   R  \n",
       "1  0.0052  0.0044   R  \n",
       "2  0.0095  0.0078   R  \n",
       "3  0.0040  0.0117   R  \n",
       "4  0.0107  0.0094   R  \n",
       "\n",
       "[5 rows x 61 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = 'https://raw.githubusercontent.com/jbrownlee/Datasets/master/sonar.csv'\n",
    "data = pd.read_csv(url, header=None)\n",
    "print(data.shape)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that we have 208 observations (sonar readings), and each observation has 60 features (energy in a particular frequency band summed over a set period of time) and a target value (rock 'R' or mine 'M').  \n",
    "\n",
    "Let's do one more thing right now, which is to set up an instance of our model.  We will use a Multi-layer Perceptron classifier (a simple form of neural network).  Don't worry about the details now, we will learn them later.  For now, you can treat this model as a black box."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of the MLPClassifier algorithm and set the hyperparameter values\n",
    "model = MLPClassifier(hidden_layer_sizes=(100,50,10),activation='tanh',\n",
    "                      solver='sgd',learning_rate_init=0.001,max_iter=2000, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Training and test sets\n",
    "In this part, you should complete the following:  \n",
    "- Split your data into a feature matrix X and a target vector y  \n",
    "- Split the data into a training set and a test set, using 85% of the data for training and 15% for testing (hint: use scikit-learn's train_test_split() method, already imported for you.  Name the resulting arrays `X_train, y_train, X_test, y_test`\n",
    "- Train (fit) your model on the X and y training sets  \n",
    "- Use your trained model to get predictions on the `X_test` test set, and name the predictions `preds`  \n",
    "- Finally, run the next code cell to calculate the display the accuracy of your classifier model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR CODE HERE ###\n",
    "# Create feature matrix using the first 60 columns as the features\n",
    "X = data.iloc[:,:60]\n",
    "\n",
    "# Create target vector from the last column\n",
    "y = data.iloc[:,60]\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(X, y, random_state=0,test_size=0.15)\n",
    "\n",
    "model.fit(X_train,y_train)\n",
    "\n",
    "preds = model.predict(X_test)\n",
    "\n",
    "### END CODE ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of our classifier on the test set is 0.812\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the performance of our model using the test predictions\n",
    "acc_test = np.sum(preds==y_test)/len(y_test)\n",
    "print('Accuracy of our classifier on the test set is {:.3f}'.format(acc_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Model selection using validation sets\n",
    "But what if we want to compare different models (for example, evaluate different algorithms or fine-tune our hyperparameters)?  Can we use the same strategy of training each model on the training data and then comparing their performance on the test set to select the best model?\n",
    "\n",
    "When we are seeking to optimize models by tuning hyperparameters or comparing different algorithms, it is a best practice to do so by comparing the performance of your model options using a \"validation\" set, and then reserve use of the test set to evaluate the performance of the final model you have selected.  To utilize this approach we must split our data three ways to create a training set, validation set, and test set.\n",
    "\n",
    "To illustrate this, let's compare two different models, which are defined for your below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of each model we want to evaluate\n",
    "\n",
    "model1 = MLPClassifier(hidden_layer_sizes=(100,50,10),activation='tanh',\n",
    "                      solver='sgd',learning_rate_init=0.001,max_iter=2000, random_state=0)\n",
    "\n",
    "model2 = MLPClassifier(hidden_layer_sizes=(100,50),activation='relu',\n",
    "                      solver='sgd',learning_rate_init=0.01,max_iter=2000, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part you should complete the following:  \n",
    "- Split your X and y arrays into a training set and a test set, using 15% of data for the test set.  Store the training data as `X_train_full, y_train_full` and the test set data as `X_test, y_test`\n",
    "- Now, split your training set again into a training set and a validation set, using 15% of the training set for the new validation set (and the remaining 85% is still available for training). Store the final training data as `X_train, y_train` and the validation set data as `X_val, y_val`\n",
    "- Train (fit) model1 and model2 using the training data only  \n",
    "- Now, use your trained model1 and model2 to generate predictions on the validation set.  Store model1's predictions as `val_preds_model1` and model2's predictions as `val_preds_model2`  \n",
    "- Finally, run the code cell below to calculate the accuracy of each on the validation set.  Based on this, which model would you select as your final model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR CODE HERE ###\n",
    "\n",
    "# Split data first into training and testing to get test set using 15% of data for test\n",
    "X_train_full,X_test,y_train_full,y_test = train_test_split(X, y, random_state=0,test_size=0.15)\n",
    "\n",
    "# Now split the training set again into training and validation, using 15% of training data for validation\n",
    "X_train,X_val,y_train,y_val = train_test_split(X_train_full,y_train_full,random_state=0,test_size=0.15)\n",
    "\n",
    "# Compare the performance of the two models using the validation set\n",
    "model1.fit(X_train,y_train)\n",
    "val_preds_model1 = model1.predict(X_val)\n",
    "\n",
    "model2.fit(X_train,y_train)\n",
    "val_preds_model2 = model2.predict(X_val)\n",
    "\n",
    "### END CODE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's compare two different models and determine which one gives us better performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of model1 on the validation set is 0.778\n",
      "Accuracy of model2 on the validation set is 0.889\n"
     ]
    }
   ],
   "source": [
    "# Calculate the validation accuracy of each model\n",
    "acc_val_model1 = np.sum(val_preds_model1==y_val)/len(y_val)\n",
    "acc_val_model2 = np.sum(val_preds_model2==y_val)/len(y_val)\n",
    "\n",
    "print('Accuracy of model1 on the validation set is {:.3f}'.format(acc_val_model1))\n",
    "print('Accuracy of model2 on the validation set is {:.3f}'.format(acc_val_model2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've chosen our final model, we can use the test set to evaluate it's performance.  Before we do that, let's retrain our model using the training plus validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of our model on the test set is 0.875\n"
     ]
    }
   ],
   "source": [
    "# Train our selected model on the training plus validation sets\n",
    "model2.fit(X_train_full,y_train_full)\n",
    "\n",
    "# Evaluate its performance on the test set\n",
    "preds_test = model2.predict(X_test)\n",
    "acc_test = np.sum(preds_test==y_test)/len(y_test)\n",
    "print('Accuracy of our model on the test set is {:.3f}'.format(acc_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Model selection using cross-validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A common approach to comparing and optimizing models is to use cross-validation rather than a single validation set to compare model performace.  We will then select the better model based on the cross-validation performance and use the test set to determine its performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPClassifier(hidden_layer_sizes=(100, 50), learning_rate_init=0.01,\n",
      "              max_iter=1000, random_state=0, solver='sgd')\n",
      "Fold accuracy: 0.780\n",
      "Fold accuracy: 0.847\n",
      "Fold accuracy: 0.845\n",
      "Mean cross-validation accuracy across all folds is 0.824 \n",
      "\n",
      "KNeighborsClassifier()\n",
      "Fold accuracy: 0.712\n",
      "Fold accuracy: 0.763\n",
      "Fold accuracy: 0.776\n",
      "Mean cross-validation accuracy across all folds is 0.750 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Let's set aside a test set and use the remainder for training and cross-validation\n",
    "X_train,X_test,y_train,y_test = train_test_split(X, y, random_state=0,test_size=0.15)\n",
    "\n",
    "# Set up the two models we want to compare: a neural network model and a KNN model\n",
    "model_a = MLPClassifier(hidden_layer_sizes=(100,50),activation='relu',\n",
    "                      solver='sgd',learning_rate_init=0.01,max_iter=1000,random_state=0)\n",
    "\n",
    "model_b = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "### YOUR CODE HERE ###\n",
    "\n",
    "# Instantiate the KFold generator which allows you to iterate through the data 3 times, splitting the data\n",
    "# into the training folds and validation fold each time\n",
    "\n",
    "kf = KFold(n_splits=3)\n",
    "\n",
    "\n",
    "# For each model, use K-folds cross validation to calculate the cross-validation accuracy\n",
    "for model in [model_a,model_b]:\n",
    "    print(model)\n",
    "    \n",
    "    # List to hold the validation fold accuracy at each iteration of the below cross-validation loop\n",
    "    acc_folds = [] \n",
    "    \n",
    "    # For each iteration, train the model on the training folds and calculate the accuracy on the validation folds\n",
    "    for (train_idx,val_idx) in kf.split(X=X_train,y=y_train):\n",
    "        \n",
    "        # Use the indices to get the training and validation sets for each fold\n",
    "        X_fold_train, X_fold_val = X_train.iloc[train_idx], X_train.iloc[val_idx]\n",
    "        y_fold_train, y_fold_val = y_train.iloc[train_idx], y_train.iloc[val_idx]\n",
    "\n",
    "        # Fit model to the training data for this iteration\n",
    "        model.fit(X_fold_train,y_fold_train)\n",
    "\n",
    "        # Get predictions for the validation fold and calculate validation fold accuracy for this iteration\n",
    "        preds = model.predict(X_fold_val)\n",
    "        acc_val = np.sum(preds==y_fold_val)/len(y_fold_val)\n",
    "        \n",
    "        print('Fold accuracy: {:.3f}'.format(acc_val))\n",
    "\n",
    "        # Add the accuracy score of this iteration to the acc_folds list\n",
    "        acc_folds.append(acc_val)\n",
    "        \n",
    "    # Calculate the mean validation accuracy across all iterations\n",
    "    mean_acc = np.mean(acc_folds)\n",
    "    \n",
    "    print('Mean cross-validation accuracy across all folds is {:.3f} \\n'.format(mean_acc))\n",
    "    \n",
    "### END CODE ###\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KFold(n_splits=3, random_state=None, shuffle=False)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPClassifier(hidden_layer_sizes=(100, 50), learning_rate_init=0.01,\n",
      "              max_iter=1000, random_state=0, solver='sgd')\n",
      "Mean cross-validation accuracy across all folds is 0.796 \n",
      "\n",
      "KNeighborsClassifier()\n",
      "Mean cross-validation accuracy across all folds is 0.756 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Alternative approach\n",
    "# Let's set aside a test set and use the remainder for training and cross-validation\n",
    "X_train,X_test,y_train,y_test = train_test_split(X, y, random_state=0,test_size=0.15)\n",
    "\n",
    "# Set up the two models we want to compare: a neural network model and a KNN model\n",
    "model_a = MLPClassifier(hidden_layer_sizes=(100,50),activation='relu',\n",
    "                      solver='sgd',learning_rate_init=0.01,max_iter=1000,random_state=0)\n",
    "\n",
    "model_b = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "# Cross-validation using cross_val_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "for model in [model_a,model_b]:\n",
    "    scores = cross_val_score(model,X_train,y_train,scoring=\"accuracy\",cv=3)\n",
    "    mean_score = np.mean(scores)\n",
    "    print(model)\n",
    "    print('Mean cross-validation accuracy across all folds is {:.3f} \\n'.format(mean_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see above, the cross-validation accuracy of model_a is higher than model_b, so we will use model_a.  Let's now evaluate the performance of model_a on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of our model on the test set is 0.875\n"
     ]
    }
   ],
   "source": [
    "# Train our selected model on the full training set\n",
    "model_a.fit(X_train,y_train)\n",
    "    \n",
    "# Evaluate its performance on the test set\n",
    "preds_test = model_a.predict(X_test)\n",
    "acc_test = np.sum(preds_test==y_test)/len(y_test)\n",
    "print('Accuracy of our model on the test set is {:.3f}'.format(acc_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
